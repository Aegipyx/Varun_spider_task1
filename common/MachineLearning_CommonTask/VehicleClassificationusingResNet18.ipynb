# Vehicle Classification using ResNet18 in Google Colab (Files Tab Version)

import os
import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.optim as optim
from torchvision.datasets import ImageFolder
from torchvision.models import resnet18
from torch.utils.data import DataLoader, random_split
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image

# Set device (use GPU if available)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Path to dataset folder uploaded in Colab Files tab
DATA_DIR = "/content/vehicles"


# Define image transformations (resize and normalize)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

# Load dataset using ImageFolder
print("Loading dataset...")
dataset = ImageFolder(DATA_DIR, transform=transform)
class_names = dataset.classes
print(f"Found classes: {class_names}")

# Split into training and validation sets
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_set, val_set = random_split(dataset, [train_size, val_size])

# Create data loaders
train_loader = DataLoader(train_set, batch_size=32, shuffle=True)
val_loader = DataLoader(val_set, batch_size=32, shuffle=False)

# Load pre-trained ResNet18 model
model = resnet18(pretrained=True)

# Modify final layer to match 7 vehicle classes
model.fc = nn.Linear(model.fc.in_features, 7)
model = model.to(device)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Train the model
print("Starting training...")
epochs = 5
for epoch in range(epochs):
    model.train()
    total_loss = 0.0
    correct = 0
    total = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    accuracy = 100 * correct / total
    print(f"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%")

# Evaluate on validation set
print("\nEvaluating on validation set...")
model.eval()
val_loss = 0.0
correct = 0
total = 0

with torch.no_grad():
    for images, labels in val_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        loss = criterion(outputs, labels)
        val_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

val_accuracy = 100 * correct / total
print(f"Validation Loss: {val_loss/len(val_loader):.4f}, Accuracy: {val_accuracy:.2f}%")

# Predict one image from each class and display the results
print("\nDisplaying sample predictions...")
fig, axes = plt.subplots(1, 7, figsize=(18, 4))
shown_classes = set()
model.eval()

for img_path, label in dataset.samples:
    if label not in shown_classes:
        img = Image.open(img_path).convert("RGB")
        input_tensor = transform(img).unsqueeze(0).to(device)
        output = model(input_tensor)
        _, pred = torch.max(output, 1)
        pred_label = class_names[pred.item()]

        ax = axes[label]
        ax.imshow(img)
        ax.set_title(f"Predicted: {pred_label}", fontsize=10)
        ax.axis('off')

        shown_classes.add(label)
        if len(shown_classes) == 7:
            break

plt.tight_layout()
plt.show()
